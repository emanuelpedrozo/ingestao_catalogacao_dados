# -*- coding: utf-8 -*-
"""CARREGAR_DADOS_CONSUME_ZONE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hROpcmuxfu1jGuX0PhoI1Qs-d9mA-a8x

# CABEÇALHO
* Nome do aluno: Emanuel Godinho Pedrozo
* Matrícula: 1415956 
* Professor: Victor Sales Silva
* Disciplina: PREPARAÇÃO E INGESTÃO DE DADOS
* Atividade: Exercício 3 - ETL & ELT (BATCH)

INSTALAÇÃO BIBLIOTECA AZURE STOREGE BLOB
"""

#pip install azure-storage-blob

import requests
import zipfile
from azure.storage.blob import BlobClient
import os
import pandas as pd
import numpy as np

"""CADEIA DE CONEXÃO"""

cadeia_conexao = 'DefaultEndpointsProtocol=https;AccountName=storageaccount1415956;AccountKey=VP3Anbpvb8xOCraYw0fllNTkc9nR/BfbmKObg+J1c+Q+lXkccsa2VZA/IO5Es7sel5HT0zKnIsOj+ASt+V2bqA==;EndpointSuffix=core.windows.net'

"""ENVIAR OS DADOS PARA AZURE STOREGE BLOB"""

dados_normalizados = '/home/azureuser/airflow/arquivos/DADOS_EXAMES_NORMALIZADOS.csv'
blob = BlobClient.from_connection_string(conn_str=cadeia_conexao, container_name="datalake-aulas", blob_name='consume/DW_Exames/DADOS_EXAMES_NORMALIZADOS.csv' )
with open(dados_normalizados, "rb") as data:
  blob.upload_blob(data)

dim_cidades = '/home/azureuser/airflow/arquivos/DIM_CIDADES.csv'
blob = BlobClient.from_connection_string(conn_str=cadeia_conexao, container_name="datalake-aulas", blob_name='consume/DW_Exames/DIM_CIDADES.csv' )
with open(dim_cidades, "rb") as data:
  blob.upload_blob(data)

dim_exames = '/home/azureuser/airflow/arquivos/DIM_EXAMES.csv'
blob = BlobClient.from_connection_string(conn_str=cadeia_conexao, container_name="datalake-aulas", blob_name='consume/DW_Exames/DIM_EXAMES.csv' )
with open(dim_exames, "rb") as data:
  blob.upload_blob(data)